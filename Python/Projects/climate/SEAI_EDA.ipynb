{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b5ce82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import csv\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ccd1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the columns to import\n",
    "columns_to_import = ['CountyName', 'DwellingTypeDescr', 'Year_of_Construction', 'TypeofRating',\n",
    "                     'EnergyRating', 'BerRating', 'GroundFloorArea(sq m)', 'FloorArea', 'NoStoreys',\n",
    "                     'MainSpaceHeatingFuel', 'MainWaterHeatingFuel', 'HSMainSystemEfficiency',\n",
    "                     'HSEffAdjFactor', 'HSSupplHeatFraction', 'HSSupplSystemEff', 'WHMainSystemEff',\n",
    "                     'WHEffAdjFactor', 'DeclaredLossFactor', 'ThermalBridgingFactor', 'LivingAreaPercent',\n",
    "                     'HESSchemeUpgrade', 'SA_Code','CO2Rating']\n",
    "\n",
    "# Specify the data types for the columns\n",
    "dtypes = {'DeclaredLossFactor': 'float64', 'SA_Code': 'object'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b68f18-cccb-4967-b14b-b4d765d108c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file and import specified columns, handling bad lines using on_bad_lines\n",
    "data = dd.read_csv('BERPublicsearch.txt', sep='\\t', encoding='latin1', usecols=columns_to_import, on_bad_lines='skip', quoting=csv.QUOTE_NONE, dtype=dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a70d874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the result\n",
    "result = data.compute()\n",
    "\n",
    "# Display the first few rows\n",
    "print(result.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb022c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of the file\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4887fbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create flags - Source https://www.sciencedirect.com/science/article/pii/S2352340920301414 (Appendix A. Supplementary data > Multimedia component 2.)\n",
    "data['Flag_MainFloorArea_0'] = (data['GroundFloorArea(sq m)'] == 0).astype(int)\n",
    "data['Flag_TotalFloorArea_less_equal_30'] = (data['GroundFloorArea(sq m)'] <= 30).astype(int)\n",
    "data['Flag_ProvisionalRemoved'] = (data['TypeofRating'] == 'Provisional').astype(int)\n",
    "data['Flag_TotalFloorArea_greater_than_1000'] = (data['GroundFloorArea(sq m)'] > 1000).astype(int)\n",
    "data['Flag_Terraced_Homes_Apartments_MainFloorArea_greater_than_500'] = ((data['DwellingTypeDescr'].isin(['End of terrace house','Mid-terrace house','Top-floor apartment','Mid-floor apartment','Basement Dwelling','Apartment','Semi-detached house','Maisonette','Ground-floor apartment'])) & (data['GroundFloorArea(sq m)'] > 500)).astype(int)\n",
    "data['Flag_HSMainSystemEfficiency_less_than_19'] = (data['HSMainSystemEfficiency'] < 19).astype(int)\n",
    "data['Flag_HSEffAdjFactor_less_than_0.7'] = (data['HSEffAdjFactor'] < 0.7).astype(int)\n",
    "data['Flag_WHMainSystemEfficiency_less_than_19_or_greater_than_450'] = ((data['WHMainSystemEff'] < 19) | (data['WHMainSystemEff'] > 450)).astype(int)\n",
    "data['Flag_WHEffAdjFactor_less_than_0.7'] = (data['WHEffAdjFactor'] < 0.7).astype(int)\n",
    "data['Flag_HSSupplSystemEfficiency_between_0_and_19'] = ((data['HSSupplSystemEff'] > 0) & (data['HSSupplSystemEff'] < 19)).astype(int)\n",
    "data['Flag_LivingAreaPercent_outside_range'] = ((data['LivingAreaPercent'] > 90) | (data['LivingAreaPercent'] < 5)).astype(int)\n",
    "data['Flag_HSSupplHeatFraction_not_in_range'] = (~data['HSSupplHeatFraction'].isin([0,0.1,0.15,0.2])).astype(int)\n",
    "data['Flag_DeclaredLossFactor_greater_than_20'] = (data['DeclaredLossFactor'] > 20).astype(int)\n",
    "data['Flag_ThermalBridgingFactor_outside_range'] = ((data['ThermalBridgingFactor'] < 0) | (data['ThermalBridgingFactor'] > 0.15)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30f618b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the result\n",
    "result = data.compute()\n",
    "\n",
    "# Display the first few rows\n",
    "print(result.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a267b5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of the file\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09f9821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by SA_Code and calculate count, sum, and average\n",
    "summary_table = result.groupby('SA_Code').agg({'SA_Code': 'count', 'HESSchemeUpgrade': 'sum', 'BerRating': 'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953692b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the columns for clarity\n",
    "summary_table.rename(columns={'SA_Code': 'Count', 'HESSchemeUpgrade': 'Sum of HESSchemeUpgrade', 'BerRating': 'Average BerRating'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439afefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the summary table\n",
    "print(summary_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d03a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the flags\n",
    "flags = ['Flag_MainFloorArea_0', 'Flag_TotalFloorArea_less_equal_30', 'Flag_ProvisionalRemoved', \n",
    "         'Flag_TotalFloorArea_greater_than_1000', 'Flag_Terraced_Homes_Apartments_MainFloorArea_greater_than_500', \n",
    "         'Flag_HSMainSystemEfficiency_less_than_19', 'Flag_HSEffAdjFactor_less_than_0.7', \n",
    "         'Flag_WHMainSystemEfficiency_less_than_19_or_greater_than_450', 'Flag_WHEffAdjFactor_less_than_0.7', \n",
    "         'Flag_HSSupplSystemEfficiency_between_0_and_19', 'Flag_LivingAreaPercent_outside_range', \n",
    "         'Flag_HSSupplHeatFraction_not_in_range', 'Flag_DeclaredLossFactor_greater_than_20', \n",
    "         'Flag_ThermalBridgingFactor_outside_range']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28d55f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by SA_Code and calculate count and sum for each flag\n",
    "flag_summary = result.groupby('SA_Code')[flags].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dad3994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with the original summary table\n",
    "summary_table_with_flags = summary_table.merge(flag_summary, on='SA_Code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ab5698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the summary table with flags\n",
    "print(summary_table_with_flags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afde84b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export data to Excel\n",
    "summary_table_with_flags.to_excel('.../summary_table_with_flags.xlsx', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41db6999",
   "metadata": {},
   "outputs": [],
   "source": [
    "#INVESTIGATE DIFFERENCES IN ORIGINAL DATA VS TOTAL ENTRIES IN OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b83c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Check for missing values in the SA_CODE column of the original result DataFrame\n",
    "missing_values = result['SA_Code'].isnull().sum()\n",
    "print(\"Number of missing values in SA_Code column:\", missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b20a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Check for duplicates in the SA_CODE column of the original result DataFrame\n",
    "duplicates = result['SA_Code'].duplicated().sum()\n",
    "print(\"Number of duplicate values in SA_Code column:\", duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acf9c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Compare the unique values in the SA_CODE column between the original result DataFrame and the grouped summary_table\n",
    "unique_sa_codes_result = result['SA_Code'].unique()\n",
    "unique_sa_codes_summary = summary_table.index.values\n",
    "print(\"Number of unique SA_Code values in result DataFrame:\", len(unique_sa_codes_result))\n",
    "print(\"Number of unique SA_Code values in summary table:\", len(unique_sa_codes_summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed71832",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['TypeofRating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e182bd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT CSO DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25aba074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Excel file - connected to small area code\n",
    "file_path = \".../CSO_DATA_2022.xlsx\"\n",
    "sheet_name = \"Unpivoted\"\n",
    "data = pd.read_excel(file_path, sheet_name=sheet_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201a984a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data based on criteria\n",
    "CSO_data = data[(data['Statistic Label'] == 'Private households') & (data['Type of Accommodation'] == 'Total') & (data['CSO Small Areas 2022'] != 'Ireland')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64039376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the sum of the VALUE column\n",
    "sum_of_value = CSO_data['VALUE'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5460a30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now CSO_data contains the desired data, and sum_of_value contains the sum of the VALUE column\n",
    "print(\"Sum of VALUE:\", sum_of_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af77ee06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group CSO_data by 'CSO Small Areas 2022' (assuming this is the column containing SA_Code) and calculate the sum of 'VALUE'\n",
    "sum_of_value_per_SA_Code = CSO_data.groupby('CSO Small Areas 2022')['VALUE'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418fdd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index of summary_table_with_flags\n",
    "summary_table_with_flags.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5717fe6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the index of summary_table_with_flags to 'SA_Code'\n",
    "summary_table_with_flags.set_index('SA_Code', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7d6e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index of sum_of_value_per_SA_Code\n",
    "sum_of_value_per_SA_Code.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d996e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the index of sum_of_value_per_SA_Code to 'CSO Small Areas 2022'\n",
    "sum_of_value_per_SA_Code.set_index('CSO Small Areas 2022', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a4fbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two dataframes on their indexes\n",
    "merged_table = summary_table_with_flags.merge(sum_of_value_per_SA_Code, left_index=True, right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed32de0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export data to Excel\n",
    "merged_table.to_excel('.../summary_table_with_value.xlsx', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdc5d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_table.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542bf4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(summary_table_with_flags.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5888c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(summary_table_with_flags.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f48dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to map mean BerRating to mean EnergyRating\n",
    "def map_to_ber_rating(mean_ber_rating):\n",
    "    if pd.isnull(mean_ber_rating):\n",
    "        return 'N/A'\n",
    "    elif mean_ber_rating <= 25:\n",
    "        return 'A1'\n",
    "    elif mean_ber_rating <= 50:\n",
    "        return 'A2'\n",
    "    elif mean_ber_rating <= 75:\n",
    "        return 'A3'\n",
    "    elif mean_ber_rating <= 100:\n",
    "        return 'B1'\n",
    "    elif mean_ber_rating <= 125:\n",
    "        return 'B2'\n",
    "    elif mean_ber_rating <= 150:\n",
    "        return 'B3'\n",
    "    elif mean_ber_rating <= 175:\n",
    "        return 'C1'\n",
    "    elif mean_ber_rating <= 200:\n",
    "        return 'C2'\n",
    "    elif mean_ber_rating <= 225:\n",
    "        return 'C3'\n",
    "    elif mean_ber_rating <= 260:\n",
    "        return 'D1'\n",
    "    elif mean_ber_rating <= 300:\n",
    "        return 'D2'\n",
    "    elif mean_ber_rating <= 340:\n",
    "        return 'E1'\n",
    "    elif mean_ber_rating <= 360:\n",
    "        return 'E2'\n",
    "    elif mean_ber_rating <= 450:\n",
    "        return 'F'\n",
    "    else:\n",
    "        return 'G'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455d00de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to create a new column 'BER_PCKG_AVE_ACTUAL_BER_RATING_CD'\n",
    "summary_table['BER_PCKG_AVE_ACTUAL_BER_RATING_CD'] = summary_table['Average BerRating'].apply(map_to_ber_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29042470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge summary_table with summary_table_with_flags based on index (SA_Code)\n",
    "summary_table_with_flags = summary_table_with_flags.merge(summary_table[['BER_PCKG_AVE_ACTUAL_BER_RATING_CD']], left_index=True, right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a508b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter result DataFrame where SA_Code is equal to '048059003'\n",
    "filtered_result = result[result['SA_Code'] == '048059003']\n",
    "\n",
    "# Display the first few rows of the filtered DataFrame\n",
    "print(filtered_result.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7013fe58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "# Step 1: Read Shapefile Data\n",
    "shapefile_path = \".../CSO_Small_Areas_-_National_Statistical_Boundaries_-_2022_-_Ungeneralised/SMALL_AREA_2022.shp\"\n",
    "gdf = gpd.read_file(shapefile_path)\n",
    "\n",
    "# Step 2: Read Excel Data from the SEAI_ALL_DATA tab\n",
    "excel_file = \"summary_table_with_value_20240229_v1.xlsx\"\n",
    "summary_df = pd.read_excel(excel_file, sheet_name=\"SEAI_ALL_DATA\")\n",
    "\n",
    "# Step 3: Merge Data\n",
    "merged_df = gdf.merge(summary_df, left_on='SA_PUB2022', right_on='SA_Code', how='left')\n",
    "\n",
    "# Step 4: Plot Choropleth Map\n",
    "\n",
    "# Define custom colormap from red to green\n",
    "colors = [(1, 0, 0), (1, 1, 0), (0, 1, 0)]  # Red to Yellow to Green\n",
    "cmap = LinearSegmentedColormap.from_list(\"CustomRedGreen\", colors, N=100)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Plot the choropleth map with adjusted parameters\n",
    "merged_df.plot(column='Percent_Availed_of_Scheme', cmap=cmap, vmin=0, vmax=0.15, linewidth=0.1, ax=ax, edgecolor='grey', legend=True)\n",
    "\n",
    "# Set title and remove axis\n",
    "ax.set_title('Percent Availed of Scheme')\n",
    "ax.axis('off')\n",
    "\n",
    "# Save the map as an image file\n",
    "plt.savefig(\".../SEAI_CSO_map.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c50660",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DUBLIN ONLY\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "# Step 1: Read Shapefile Data\n",
    "shapefile_path = \".../CSO_Small_Areas_-_National_Statistical_Boundaries_-_2022_-_Ungeneralised/SMALL_AREA_2022.shp\"\n",
    "gdf = gpd.read_file(shapefile_path)\n",
    "\n",
    "# Filter data for County Dublin only\n",
    "county_dublin_gdf = gdf[gdf['COUNTY_ENG'] == 'DUBLIN CITY']\n",
    "\n",
    "# Step 2: Read Excel Data from the SEAI_ALL_DATA tab\n",
    "excel_file = \"summary_table_with_value_20240229_v1.xlsx\"\n",
    "summary_df = pd.read_excel(excel_file, sheet_name=\"SEAI_ALL_DATA\")\n",
    "\n",
    "# Step 3: Merge Data\n",
    "merged_df = county_dublin_gdf.merge(summary_df, left_on='SA_PUB2022', right_on='SA_Code', how='left')\n",
    "\n",
    "# Step 4: Plot Choropleth Map\n",
    "\n",
    "# Define custom colormap from red to green\n",
    "colors = [(1, 0, 0), (1, 1, 0), (0, 1, 0)]  # Red to Yellow to Green\n",
    "cmap = LinearSegmentedColormap.from_list(\"CustomRedGreen\", colors, N=100)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Plot the choropleth map with adjusted parameters\n",
    "merged_df.plot(column='Percent_Availed_of_Scheme', cmap=cmap, vmin=0, vmax=0.15, linewidth=0.1, ax=ax, edgecolor='grey', legend=True)\n",
    "\n",
    "# Set title and remove axis\n",
    "ax.set_title('Percent Availed of Scheme in County Dublin')\n",
    "ax.axis('off')\n",
    "\n",
    "# Save the map as an image file\n",
    "plt.savefig(\".../County_Dublin_Map.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331f84f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PPR GEOCODING #\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "def geocode_address(address):\n",
    "    url = f'https://nominatim.openstreetmap.org/search?q={address}&format=json'\n",
    "    response = requests.get(url, verify=False)  # Disabling SSL certificate verification\n",
    "    print(\"Response content:\", response.content)  # Print the response content\n",
    "    data = response.json()\n",
    "\n",
    "    if data:\n",
    "        latitude = float(data[0]['lat'])\n",
    "        longitude = float(data[0]['lon'])\n",
    "        return latitude, longitude\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "csv_file = r'...\\PPR_ALL_March2024.csv'\n",
    "data = pd.read_csv(csv_file, encoding='latin1')\n",
    "\n",
    "# Rename the 'Date of Sale (dd/mm/yyyy)' column to 'Date of Sale'\n",
    "data.rename(columns={'Date of Sale (dd/mm/yyyy)': 'Date of Sale'}, inplace=True)\n",
    "\n",
    "# Sort the DataFrame based on 'Date of Sale' in descending order to get the most recent entries\n",
    "data['Date of Sale'] = pd.to_datetime(data['Date of Sale'], format='%d/%m/%Y')\n",
    "data.sort_values(by='Date of Sale', ascending=False, inplace=True)\n",
    "\n",
    "# Limit the DataFrame to the most recent 2500 entries\n",
    "data = data.head(2500)\n",
    "\n",
    "# Iterate over each row in the DataFrame and geocode the address\n",
    "for index, row in data.iterrows():\n",
    "    address = row['Address']\n",
    "    result = geocode_address(address)\n",
    "    if result is not None:\n",
    "        latitude, longitude = result\n",
    "        data.at[index, 'Latitude'] = latitude\n",
    "        data.at[index, 'Longitude'] = longitude\n",
    "    else:\n",
    "        data.at[index, 'Latitude'] = None\n",
    "        data.at[index, 'Longitude'] = None\n",
    "\n",
    "# Save the updated DataFrame with latitude and longitude to a new CSV file\n",
    "output_file = r'...\\PPR_ALL_March2024_geocoded.csv'\n",
    "data.to_csv(output_file, index=False)\n",
    "\n",
    "print(\"Geocoding completed. Results saved to:\", output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943b473d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECK MATCHES BETWEEN SEAI AND BER CERT DATA#\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Read data from Excel file\n",
    "ber_certs_data = pd.read_excel('.../BER_CERTS_March2024_V2.xlsx')\n",
    "\n",
    "# Select required columns\n",
    "ber_certs_subset = ber_certs_data[['BERNumber', 'EnergyRating', 'FloorArea', 'YearOfConstruction','ResearchMatchKey']]\n",
    "\n",
    "\n",
    "# Concatenate values from existing columns to create ResearchMatchKey\n",
    "result['ResearchMatchKey'] = (result['DwellingTypeDescr'] + '|' +\n",
    "                              result['Year_of_Construction'].astype(str) + '|' +\n",
    "                              result['GroundFloorArea(sq m)'].apply(lambda x: '{:.3f}'.format(x)) + '|' +\n",
    "                              result['EnergyRating'].astype(str) + '|' +\n",
    "                              result['BerRating'].apply(lambda x: '{:.3f}'.format(x)) + '|' +\n",
    "                              result['CO2Rating'].apply(lambda x: '{:.2f}'.format(x)))\n",
    "\n",
    "# Merge data with result DataFrame on matching values\n",
    "merged_data = pd.merge(result, ber_certs_subset, how='inner',\n",
    "                       left_on=['ResearchMatchKey'],\n",
    "                       right_on=['ResearchMatchKey'])\n",
    "\n",
    "\n",
    "# Now merged_data contains only the rows where EnergyRating, FloorArea, and YearOfConstruction match between the two datasets\n",
    "\n",
    "# Create flags in merged_data\n",
    "merged_data['Flag_MainFloorArea_0'] = (merged_data['GroundFloorArea(sq m)'] == 0).astype(int)\n",
    "merged_data['Flag_TotalFloorArea_less_equal_30'] = (merged_data['GroundFloorArea(sq m)'] <= 30).astype(int)\n",
    "merged_data['Flag_ProvisionalRemoved'] = (merged_data['TypeofRating'] == 'Provisional').astype(int)\n",
    "merged_data['Flag_TotalFloorArea_greater_than_1000'] = (merged_data['GroundFloorArea(sq m)'] > 1000).astype(int)\n",
    "merged_data['Flag_Terraced_Homes_Apartments_MainFloorArea_greater_than_500'] = (\n",
    "(merged_data['DwellingTypeDescr'].isin(['End of terrace house', 'Mid-terrace house', 'Top-floor apartment', 'Mid-floor apartment', 'Basement Dwelling', 'Apartment', 'Semi-detached house', 'Maisonette', 'Ground-floor apartment'])) &\n",
    "(merged_data['GroundFloorArea(sq m)'] > 500)\n",
    ").astype(int)\n",
    "merged_data['Flag_HSMainSystemEfficiency_less_than_19'] = (merged_data['HSMainSystemEfficiency'] < 19).astype(int)\n",
    "merged_data['Flag_HSEffAdjFactor_less_than_0.7'] = (merged_data['HSEffAdjFactor'] < 0.7).astype(int)\n",
    "merged_data['Flag_WHMainSystemEfficiency_less_than_19_or_greater_than_450'] = (\n",
    "(merged_data['WHMainSystemEff'] < 19) | (merged_data['WHMainSystemEff'] > 450)\n",
    ").astype(int)\n",
    "merged_data['Flag_WHEffAdjFactor_less_than_0.7'] = (merged_data['WHEffAdjFactor'] < 0.7).astype(int)\n",
    "merged_data['Flag_HSSupplSystemEfficiency_between_0_and_19'] = (\n",
    "(merged_data['HSSupplSystemEff'] > 0) & (merged_data['HSSupplSystemEff'] < 19)\n",
    ").astype(int)\n",
    "merged_data['Flag_LivingAreaPercent_outside_range'] = (\n",
    "(merged_data['LivingAreaPercent'] > 90) | (merged_data['LivingAreaPercent'] < 5)\n",
    ").astype(int)\n",
    "merged_data['Flag_HSSupplHeatFraction_not_in_range'] = (\n",
    "~merged_data['HSSupplHeatFraction'].isin([0, 0.1, 0.15, 0.2])\n",
    ").astype(int)\n",
    "merged_data['Flag_DeclaredLossFactor_greater_than_20'] = (merged_data['DeclaredLossFactor'] > 20).astype(int)\n",
    "merged_data['Flag_ThermalBridgingFactor_outside_range'] = (\n",
    "(merged_data['ThermalBridgingFactor'] < 0) | (merged_data['ThermalBridgingFactor'] > 0.15)\n",
    ").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8615c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path where you want to save the merged data Excel file\n",
    "output_file_path = '.../merged_data.xlsx'\n",
    "\n",
    "# Save the merged data to an Excel file\n",
    "merged_data.to_excel(output_file_path, index=False)\n",
    "\n",
    "print(\"Merged data has been saved to:\", output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4a131b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
