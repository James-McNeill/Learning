{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62e757d9-d3cb-4cc1-8df4-2e68c7548741",
   "metadata": {},
   "source": [
    "## German Credit Data\n",
    "\n",
    "Model development with imbalanced data for classification\n",
    "\n",
    "Example will initial use the german credit data.\n",
    "\n",
    "[ML tutorial](https://machinelearningmastery.com/imbalanced-classification-of-good-and-bad-credit/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd4a5a1-5b78-4107-8cfc-db45a178ee3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdcae57-f27f-4ac5-8084-968ecad7e3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "df = pd.read_csv(\"german_credit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f83f0f-c6f8-4262-9444-20048c12f836",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cfc1c3-074a-43d7-83c0-c26a3621b27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79238c54-873f-4929-b5d4-2a491eb8dea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427aa502-a33d-46b7-9797-e5e3fc1e19ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d374eb33-5d5b-4aa6-8c9f-ffe43cb4fd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='all').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0311253b-3ede-4bcb-86ca-6a3a1dbf39c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test harness and baseline model evaluation for the german credit dataset\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# load the dataset\n",
    "def load_dataset(full_path):\n",
    "    # load the dataset as a numpy array\n",
    "    dataframe = pd.read_csv(full_path)\n",
    "    # split into inputs and outputs\n",
    "    X, y = dataframe.drop(['Credit_risk'], axis=1), dataframe['Credit_risk']\n",
    "    # select categorical features\n",
    "    cat_ix = X.select_dtypes(include=['object', 'bool']).columns\n",
    "    # one hot encode cat features only\n",
    "    ct = ColumnTransformer([('o',OneHotEncoder(),cat_ix)], remainder='passthrough')\n",
    "    X = ct.fit_transform(X)\n",
    "    # label encode the target variable to have the classes 0 and 1\n",
    "    mapping = {'GOOD': 0, 'BAD': 1}\n",
    "    # y = LabelEncoder().fit_transform(y)\n",
    "    y = y.replace(mapping)\n",
    "    return X, y\n",
    "\n",
    "# calculate f2 score\n",
    "def f2(y_true, y_pred):\n",
    "    return fbeta_score(y_true, y_pred, beta=2)\n",
    "\n",
    "# evaluate a model\n",
    "def evaluate_model(X, y, model):\n",
    "    # define evaluation procedure\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    # define the model evaluation metric\n",
    "    metric = make_scorer(f2)\n",
    "    # evaluate model\n",
    "    scores = cross_val_score(model, X, y, scoring=metric, cv=cv, n_jobs=-1)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f484a7b-f86f-4ee4-8687-c54e29a60546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the location of the dataset\n",
    "full_path = 'german_credit.csv'\n",
    "# load the dataset\n",
    "X, y = load_dataset(full_path)\n",
    "# summarize the loaded dataset\n",
    "print(X.shape, y.shape, Counter(y))\n",
    "# define the reference model\n",
    "model = DummyClassifier(strategy='constant', constant=1)\n",
    "# evaluate the model\n",
    "scores = evaluate_model(X, y, model)\n",
    "# summarize performance\n",
    "print('Mean F2: %.3f (%.3f)' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9715d096-54e0-426c-b2f9-f412995ae525",
   "metadata": {},
   "source": [
    "### Evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d55d6f2-5ba0-4d5b-8bf1-df4161151996",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# model dictionary\n",
    "model_dict = {\n",
    "    'LR': {'model': LogisticRegression(solver='liblinear')},\n",
    "    'LDA': {'model': LinearDiscriminantAnalysis()},\n",
    "    'NB': {'model': GaussianNB()},\n",
    "    'GPC': {'model': GaussianProcessClassifier()},\n",
    "    'SVM': {'model': SVC(gamma='scale')},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4323eb7-6502-4d81-b702-38b34479e911",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m, d in model_dict.items():\n",
    "    print(d['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a7b4cb-ad56-44ed-89ba-ebd8241e7d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "def load_dataset1(full_path):\n",
    "    # load the dataset as a numpy array\n",
    "    dataframe = pd.read_csv(full_path)\n",
    "    # split into inputs and outputs\n",
    "    X, y = dataframe.drop(['Credit_risk'], axis=1), dataframe['Credit_risk']\n",
    "    # select categorical features\n",
    "    cat_ix = X.select_dtypes(include=['object', 'bool']).columns\n",
    "    num_ix = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "    # label encode the target variable to have the classes 0 and 1\n",
    "    mapping = {'GOOD': 0, 'BAD': 1}\n",
    "    y = y.replace(mapping)\n",
    "    return X, y, cat_ix, num_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f530e55d-d3be-4120-8edf-bef19d559022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to create scores from model dictionary\n",
    "def model_run(X, y, cat_ix, num_ix, ):\n",
    "    result = list()\n",
    "    for model_name, model_param in model_dict.items():\n",
    "        ct = ColumnTransformer([('c',OneHotEncoder(),cat_ix), ('n',MinMaxScaler(),num_ix)])\n",
    "        pipeline = Pipeline(steps=[('t',ct), ('m',model_param['model'])])\n",
    "        scores = evaluate_model(X, y, pipeline)\n",
    "        result.append({\n",
    "            'model':model_name,\n",
    "            'mean_score':np.mean(scores),\n",
    "            'std_score':np.std(scores)\n",
    "        })\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247d0fd3-eab9-41a9-a145-3f42b7beb7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the location of the dataset\n",
    "full_path = 'german_credit.csv'\n",
    "# load the dataset\n",
    "X, y, cat_ix, num_ix = load_dataset1(full_path)\n",
    "# evaluate the model\n",
    "scores = model_run(X, y, cat_ix, num_ix)\n",
    "# summarize performance\n",
    "df_scores = pd.DataFrame(scores, columns=['model', 'mean_score', 'std_score'])\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0fd1f7-58f7-43c1-b872-e85ccc260c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results - only showing the mean as the model_run function has taken average from all scores\n",
    "df_scores.boxplot(column='mean_score', by='model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3f4c20-f467-40a9-bdf2-200debbc35cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
